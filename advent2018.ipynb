{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2018\n",
    "\n",
    "Hey there! For this year of Advent of Code, I'm going to be trying to journal my progress through the month's problems using a Python notebook, inspired by the similar notebooks of [Peter Norvig](https://github.com/norvig/pytudes). I've considered doing other things this year, like perhaps using the Advent of Code as an excuse to learn a new language, but last year I only completed the first 8, so I figured I should focus on first trying to complete all of this year's problems before getting ahead of myself. (Plus, the easier challenges make for good interview problem practice, so it fits in with my current goals).\n",
    "\n",
    "Since I'm very comfortable with Python, I'm going to try to be competitive with timing (as the time to write code is the main bottleneck typically - not the program execution), so I will try to finish on the leaderboard. But this is my first time using an Python notebook, so there's a chance this will slow me down. Better hope for the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 0: Imports and utilities\n",
    "\n",
    "Following the inspiration of Peter Norvig, here I will try to put some code and imports that I think could be useful. For now I'll just include libraries and functions I've used a decent amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from heapq import heappush, heappop\n",
    "from itertools import accumulate, combinations, cycle, takewhile\n",
    "\n",
    "# source: https://stackoverflow.com/a/30558049\n",
    "def unique_permutations(elements):\n",
    "    if len(elements) == 1:\n",
    "        yield (elements[0],)\n",
    "    else:\n",
    "        unique_elements = set(elements)\n",
    "        for first_element in unique_elements:\n",
    "            remaining_elements = list(elements)\n",
    "            remaining_elements.remove(first_element)\n",
    "            for sub_permutation in unique_permutations(remaining_elements):\n",
    "                yield (first_element,) + sub_permutation\n",
    "\n",
    "def flatten(lst):\n",
    "    return [elem for sublst in lst for elem in sublst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 1](https://adventofcode.com/2018/day/1): Chronal Calibration\n",
    "\n",
    "This problem was very straight forward. Getting a tight time is just a matter of having your environment setup, and fortunately I don't think using jupyter really slowed me down much, as I already had prepared some starter code in advance for reading in input.\n",
    "\n",
    "Unfortunately, I took 1:48 to solve the first star, but to get in the top 100 I would have needed 1:32; and I took 6:32 on the second star, but to get in the top 100 I would have needed 5:28. Besides reading the problem as a bottleneck, during the second problem I was planning to loop over indices but ended up looping over values, so I ended up with an incorrect answer costing me a minute. Also, my code definitely looks pretty sloppy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556\n",
      "448\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input1.txt') as f:\n",
    "    X = list(map(int, f.read().split()))\n",
    "\n",
    "print(sum(X))\n",
    "\n",
    "# second star\n",
    "\n",
    "freqs = set()\n",
    "curr = 0\n",
    "while True:\n",
    "    found = False\n",
    "    for x in X:\n",
    "        curr += x\n",
    "        if curr in freqs:\n",
    "            found = True\n",
    "            print(curr)\n",
    "            break\n",
    "        freqs.add(curr)\n",
    "    if found:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how I would refactor the second star with a few extra minutes to spare. The interesting thing about this kind of problem is that it seems simple enough that it should be doable with a Python one-or-two-liner, but I don't have an exact intuition for it (though I'm sure someone on Reddit has done it). That said, I think for most people this type of problem feels easier to solve this with iterative methods than functional programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n"
     ]
    }
   ],
   "source": [
    "# second star\n",
    "\n",
    "freqs = set()\n",
    "for x in accumulate(cycle(X)):\n",
    "    if x in freqs:\n",
    "        print(x)\n",
    "        break\n",
    "    freqs.add(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 2](https://adventofcode.com/2018/day/2): Inventory Management System\n",
    "\n",
    "Unfortunately, I didn't have this time to do this challenge at midnight, so I can't really comment on speed for these questions, though they were only slightly more involved than Day 1. The first star is very easily solvable in Python using the Counter library function from the collections module - it's useful in quite a number of coding interview puzzles, in my experience.\n",
    "\n",
    "The second star involves a bit more work, as it seems to necessitate comparing all pairs of strings against one another to decide which differs exactly by one character. Both parts, calculating the number of differences, and deriving the string in common, can be simplified as Python one-liners without adding much unnecessary overhead. Writing Python one-liners tend to just feel satisfying to derive and look clean to look at, even though they don't always reflect how a person came up with the line.\n",
    "\n",
    "It's worth noting how out of habit (from websites like HackerRank and LeetCode), I tend to code defensively, doing things like iterating only through the minimum of the lengths of the two strings, even though all strings in the given input are the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7192\n",
      "mbruvapghxlzycbhmfqjonsie\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input2.txt') as f:\n",
    "    X = f.read().split()\n",
    "\n",
    "twos, threes = 0, 0\n",
    "for x in X:\n",
    "    count = Counter(x)\n",
    "    if 2 in count.values():\n",
    "        twos += 1\n",
    "    if 3 in count.values():\n",
    "        threes += 1\n",
    "print(twos * threes)\n",
    "\n",
    "# second star\n",
    "\n",
    "def num_differences(s1, s2):\n",
    "    return sum([s1[i] != s2[i] for i in range(min(len(s1), len(s2)))])\n",
    "\n",
    "def in_common(s1, s2):\n",
    "    return ''.join([s1[i] for i in range(min(len(s1), len(s2))) if s1[i] == s2[i]])\n",
    "\n",
    "for i in range(len(X)):\n",
    "    for j in range(i + 1, len(X)):\n",
    "        if num_differences(X[i], X[j]) == 1:\n",
    "            print(in_common(X[i], X[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 3](https://adventofcode.com/2018/day/3): No Matter How You Slice It\n",
    "\n",
    "That was satisfying for sure! I ended up solving this puzzle using a simple brute force approach, storing all of the positions in a grid and then performing the necessary operations to update the grid with appropriate ownership of the squares. For the second star, my first solution made the answer relatively easy to retrieve, since it just required me to iterate over in the same fashion and re-check the ownership of various regions.\n",
    "\n",
    "Unfortunately, the main part I got stuck on was something I should probably be fluent with: input parsing. I knew how to use string.split() to separate the lines, but the complex format of the output made regex a clear candidate for the problem. That said, I haven't necessarily used regex a lot, so I was originally looking up ways to separate strings by multiple separators in Python, before deciding that just gathering all of the sequences of digits would be more efficient.\n",
    "\n",
    "The other slight slowdown was that at the very end I remembered I had to flatten the list (or at least flattening would make for the cleanest solution), and I hadn't written a function for it in advance. Once these issues were figured out though, most of the coding was smooth sailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113966\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input3.txt') as f:\n",
    "    X = f.read().split('\\n')[0:-1]  # remove the last line, which is empty\n",
    "\n",
    "grid = [[None] * 1000 for _ in range(1000)]\n",
    "for x in X:\n",
    "    a, b, c, d, e = map(int, re.findall('\\d+', x))\n",
    "    for row in range(c, c + e):\n",
    "        for col in range(b, b + d):\n",
    "            if grid[row][col] is None:\n",
    "                grid[row][col] = a\n",
    "            else:\n",
    "                grid[row][col] = 'X'\n",
    "\n",
    "print(sum([f == 'X' for f in flatten(grid)]))\n",
    "\n",
    "# second star\n",
    "\n",
    "for x in X:\n",
    "    a, b, c, d, e = map(int, re.findall('\\d+', x))\n",
    "    safe = True\n",
    "    for row in range(c, c + e):\n",
    "        for col in range(b, b + d):\n",
    "            if grid[row][col] == 'X':\n",
    "                safe = False\n",
    "                break\n",
    "        if not safe:\n",
    "            break\n",
    "    if safe:\n",
    "        print(a)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 4](https://adventofcode.com/2018/day/4): Repose Record\n",
    "\n",
    "This update is quite delayed, but as I became preoccupied with final exams, I had to take a temporary hiatus on Advent of Code. But now that I am on holiday break, there is more time to complete these challenges (though I won't be competing for leaderboard positions). Anyway, onward to the puzzle!\n",
    "\n",
    "As with Day 3, I was slowed down a bit by first figuring out what the most efficient way to parse the data was. I used regular expressions again this time, but instead of splitting the string, I just used re.match while specifying groups in my pattern (using parentheses) so I could extract individual groups into tuples. I'm not sure if this is necessarily the most efficient method, but it's fairly readable and understandable, so I think it works fine. Since the time stamps of each string are fixed in size, it now occurs to me that I could probably have just picked slices out of the strings for the times, but I would still have to search for the guard IDs on the \"begins shift\" records.\n",
    "\n",
    "The rest of the calculation itself was fairly simple. Once I extracted the data into tuples (ordered by month, day, hour, minute), sorting in Python automatically places all of the records in the right order. Then I stored individual data for guards using a dictionary, associating an array of 60 integers for each guard. Once I determined the time interval during which a guard was sleeping, I simply incremented the corresponding entries of the array. It's possible this could be handled more efficiently somehow (perhaps with some variant of range queries?) but for a list of size 60, we can sleep safely at night. After we have the sleeping data for each guard, calculating the most-slept minutes (and the total time they spent sleeping) was easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39698\n",
      "14920\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input4.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "records = []\n",
    "for line in lines:\n",
    "    m = re.match(r\"\\[\\d\\d\\d\\d-(\\d\\d)-(\\d\\d) (\\d\\d):(\\d\\d)\\] (.*)\", line)\n",
    "    records.append((int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4)), m.group(5)))\n",
    "\n",
    "# generate guard data\n",
    "records = sorted(records)\n",
    "guard_data = dict()  # dictionary mapping guard ID's (ints) to length-60 arrays of sleep frequencies\n",
    "curr_guard = -1\n",
    "sleeping = -1\n",
    "for record in records:\n",
    "    m = re.search(r\"\\d+\", record[4])\n",
    "    if m:  # \"Begin shift\" record\n",
    "        curr_guard = int(m.group(0))\n",
    "        if curr_guard not in guard_data:\n",
    "            guard_data[curr_guard] = [0] * 60\n",
    "    elif record[4] == 'falls asleep':  # \"falls asleep\" record\n",
    "        sleeping = record[3]\n",
    "    elif record[4] == 'wakes up':  # \"wakes up\" record\n",
    "        for i in range(sleeping, record[3]):\n",
    "            guard_data[curr_guard][i] += 1\n",
    "    else:\n",
    "        raise Exception('could not read data: {}'.format(record))\n",
    "        \n",
    "# process guard data\n",
    "best_id = ''\n",
    "best_total = 0\n",
    "best_minute = 0\n",
    "for guard in guard_data:\n",
    "    total = sum(guard_data[guard])\n",
    "    if total > best_total:\n",
    "        best_id = guard\n",
    "        best_total = total\n",
    "        best_minute = guard_data[guard].index(max(guard_data[guard]))\n",
    "\n",
    "print(best_id * best_minute)\n",
    "\n",
    "# second star\n",
    "\n",
    "best_id = ''\n",
    "best_freq = 0\n",
    "best_minute = 0\n",
    "for guard in guard_data:\n",
    "    freq = max(guard_data[guard])\n",
    "    if freq > best_freq:\n",
    "        best_id = guard\n",
    "        best_freq = freq\n",
    "        best_minute = guard_data[guard].index(freq)\n",
    "\n",
    "print(best_id * best_minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 5](https://adventofcode.com/2018/day/5) : Alchemical Reduction\n",
    "\n",
    "For the first star, my initial instinct was to try and somehow convert the string into a data structure which allowed constant time intermediate deletions, like a doubly-linked list. But as it happens, doubly-linked lists aren't natively available in Python, and creating a datastructure for this didn't seem like it would be very efficient (unless I was using a lower level language like C/C++/Rust perhaps).\n",
    "\n",
    "Fortunately, I realized I could accomplish the task easier if I just used a stack to continuously add elements to the \"result\" string, just checking if anything reacts with the top element in the stack. When one imagines the long chemical chain reacting in a vacuum, the first image that comes to my mind is a long line which slowly collapses inwards - but when you view it just from one side, the iterative approach clearly doesn't miss out on any reactions. This result can probably be shown easily using some form of proof by induction or contradiction.\n",
    "\n",
    "For the second star, I reused the same approach to simply iterate through the newly reduced string with a stack, but additionally checking if the character I am currently reading is a fixed target letter (e.g. 'a'), in which case I ignore it and move to the next character. I repeat this for every possible fixed letter, and keep track of what the lowest string length I obtained overall was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10564\n",
      "6336\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input5.txt') as f:\n",
    "    X = f.readline().strip()\n",
    "\n",
    "stack = []\n",
    "for char in X:\n",
    "    if not stack:  # stack is empty\n",
    "        stack.append(char)\n",
    "    else:\n",
    "        e1 = stack[-1]\n",
    "        e2 = char\n",
    "        if e1.lower() == e2.lower() and \\\n",
    "                ((e1 == e1.lower() and e2 == e2.upper()) or \\\n",
    "                 (e1 == e1.upper() and e2 == e2.lower())):\n",
    "            stack.pop()\n",
    "        else:\n",
    "            stack.append(char)\n",
    "\n",
    "print(len(stack))\n",
    "\n",
    "# second star\n",
    "\n",
    "min_length = len(stack)\n",
    "for letter in string.ascii_lowercase:\n",
    "    new_stack = []\n",
    "    for char in stack:\n",
    "        if char == letter or char == letter.upper():\n",
    "            continue\n",
    "        elif not new_stack:\n",
    "            new_stack.append(char)\n",
    "        else:\n",
    "            e1 = new_stack[-1]\n",
    "            e2 = char\n",
    "            if e1.lower() == e2.lower() and \\\n",
    "                    ((e1 == e1.lower() and e2 == e2.upper()) or \\\n",
    "                     (e1 == e1.upper() and e2 == e2.lower())):\n",
    "                new_stack.pop()\n",
    "            else:\n",
    "                new_stack.append(char)\n",
    "    min_length = min(min_length, len(new_stack))\n",
    "\n",
    "print(min_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 6](https://adventofcode.com/2018/day/6): Chronal Coordinates\n",
    "\n",
    "This problem certainly off the bat seemed like a large difficulty spike compared to the previous puzzles. The problem was additionally challenging since I originally went down some incorrect paths, after intuitively thinking about the problem initially in terms of euclidaen distance, even though it actually specifies Manhattan distance to be used.\n",
    "\n",
    "Nonetheless, to start off this puzzle I began trying to think of how I could identify which points had areas that were finite. After some thinking (initially with the assumption of using Euclidean distance), I first realized that any point with finite area must be in some way \"enclosed\" by a polygon formed by other points, and moreover, there has to be a triangle of other points that enclose it. So if for each point I iterated over all triples of other points, and if I could easily calculate if one point was within a triangle of other points, then I could determine which points have bounded areas. (Calculating this is not trivial, but I found a StackOverfloow post offering an easy calculation for if a point is within a 2D triangle, and willingly borrowed it for my educational use).\n",
    "\n",
    "Later on, after realizing I had to use Manhattan distance, I had to reconsider this \"finite area\" identification subproblem, as the triangle-based solution no longer worked. One thing I noticed was that the diagrams formed by the points were very clearly Voronoi diagrams, as like the one shown in [this picture](https://commons.wikimedia.org/wiki/File:Manhattan_Voronoi_Diagram.svg). After enough studying of the picture, I concluded for a point to have finite area, then when considering the four diagonal quadrants surrounding the point (that is, visualized like the cartesian quadrants but at a 45 degree angle), there must be at least one point in each of the quadrants, assuming we label each point as the center of its four quadrants. So in a similar fashion as with the triangle idea, I iterated through all 4-combinations of points, and checked which would satisfy this four-quadrant constraint. (The exact checking method can be seen in the `point_in_diamond` function). Fortunately, as the input given only includes 50 points, 50^5 is just small enough number of iterations to be practical to handle all the combinations. Now, we have identified which of the 50 points will have finite areas.\n",
    "\n",
    "Also after inspecting the input, I noticed that all 50 of the input points were within roughly a 400x400 grid space. This makes for about 160,000 individual \"locations\" on the grid, for which it would not be that expensive to calculate which input point each location is closest to. From here, it's just a matter of summing the number of locations associated with each input point, filtering out the input points with infinite space, and taking the maximum out of all of them to get the answer!\n",
    "\n",
    "For the second star, the solution was easier as it just involve checking which points were within the constrained distance. Naturally, I just iterated over all of the locations, added the distance to each of the given points, and checked whether each was within the required constraint.\n",
    "\n",
    "Overall the code I wrote takes a while to run - around 30 seconds to a minute it seems, so I reckon there are probably some much more efficient algorithms for the problem. But I really enjoyed this challenge as a whole!\n",
    "\n",
    "Edit: Thanks to a kind suggestion of a friend, I was able to optimize the finite-area identification part of my algorithm from O(N^5) to O(N^2) (where N is the number of points). The trick is that we only actually need to identify the quadrant of each point once, to see if there is a point in the given quadrant. Thus, we do not actually have to know which four-tuple of points make up the quadrant. This allows me to calculate the solution to both parts within about 15 seconds now (with less than a second going towards the finite area calculation), so this is a substantial improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, False, True, True, False, False, False, True, False, False, False, True, False, False, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, False, False, False, False, False, True, False, True, True, True, True, True, False, True, True]\n",
      "3722\n",
      "44634\n"
     ]
    }
   ],
   "source": [
    "# test = \"\"\"1, 1\n",
    "# 1, 6\n",
    "# 8, 3\n",
    "# 3, 4\n",
    "# 5, 5\n",
    "# 8, 9\n",
    "# \"\"\"\n",
    "\n",
    "# X = test.split('\\n')[:-1]\n",
    "\n",
    "GRID_SIZE = 400\n",
    "\n",
    "with open('input/input6.txt') as f:\n",
    "    X = f.read().split('\\n')[:-1]  # remove last entry corresponding to empty line\n",
    "\n",
    "# points are stored as a list of coordinate tuples\n",
    "points = list(map(lambda x: tuple(map(int, x.split(', '))), X))\n",
    "\n",
    "def left_quad(x, test):\n",
    "    return test[0] < x[0] and abs(test[1] - x[1]) < (x[0] - test[0])\n",
    "\n",
    "def right_quad(x, test):\n",
    "    return test[0] > x[0] and abs(test[1] - x[1]) < (test[0] - x[0])\n",
    "\n",
    "def top_quad(x, test):\n",
    "    return test[1] > x[1] and abs(test[0] - x[0]) < (test[1] - x[1])\n",
    "\n",
    "def bottom_quad(x, test):\n",
    "    return test[1] < x[1] and abs(test[0] - x[0]) < (x[1] - test[1])\n",
    "\n",
    "# calculate which points have finite area\n",
    "finite = [False] * len(points)\n",
    "for i, point in enumerate(points):\n",
    "    l = r = t = b = False\n",
    "    for test_point in points:\n",
    "        if left_quad(point, test_point):\n",
    "            l = True\n",
    "        elif right_quad(point, test_point):\n",
    "            r = True\n",
    "        elif top_quad(point, test_point):\n",
    "            t = True\n",
    "        elif bottom_quad(point, test_point):\n",
    "            b = True\n",
    "    if l and r and t and b:\n",
    "        finite[i] = True\n",
    "\n",
    "# this is about the half way point of the calculation,\n",
    "# so its nice to get an update things are working!\n",
    "print(finite)\n",
    "\n",
    "def manhattan_dist(p0, p1):\n",
    "    return abs(p1[0] - p0[0]) + abs(p1[1] - p0[1])\n",
    "\n",
    "# calculate which point is closest for each location in the grid\n",
    "grid = [[-1] * GRID_SIZE for _ in range(GRID_SIZE)]\n",
    "for i in range(GRID_SIZE):\n",
    "    for j in range(GRID_SIZE):\n",
    "        shortest_index = 0\n",
    "        shortest_dist = 2 * GRID_SIZE * GRID_SIZE\n",
    "        for k in range(len(points)):\n",
    "            dist = manhattan_dist(points[k], (i, j))\n",
    "            if dist < shortest_dist:\n",
    "                shortest_dist = dist\n",
    "                shortest_index = k\n",
    "            elif dist == shortest_dist:  # avoid ties\n",
    "                shortest_index = -1\n",
    "        grid[i][j] = shortest_index\n",
    "\n",
    "# calculate which point (with finite area) has the most locations closest to it\n",
    "flat_grid = [entry for row in grid for entry in row]\n",
    "best_point = 0\n",
    "best_count = 0\n",
    "for i in range(len(points)):\n",
    "    if not finite[i]:\n",
    "        continue\n",
    "    count = sum(map(lambda x: x == i, flat_grid))\n",
    "    if count > best_count:\n",
    "        best_count = count\n",
    "        best_point = i\n",
    "\n",
    "print(best_count)\n",
    "\n",
    "# second star\n",
    "\n",
    "TOTAL_DISTANCE = 10000\n",
    "\n",
    "# store a grid indicating which positions are \"centralized\",\n",
    "# i.e. within the total distance constraint\n",
    "central = [[False] * GRID_SIZE for _ in range(GRID_SIZE)]\n",
    "for i in range(GRID_SIZE):\n",
    "    for j in range(GRID_SIZE):\n",
    "        total = 0\n",
    "        for k, point in enumerate(points):\n",
    "            total += manhattan_dist(points[k], (i, j))\n",
    "        if total < TOTAL_DISTANCE:\n",
    "            central[i][j] = True\n",
    "\n",
    "flat_central = [entry for row in central for entry in row]\n",
    "print(sum(flat_central))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Day 7](https://adventofcode.com/2018/day/7): The Sum of Its Parts\n",
    "\n",
    "The first star for this challenge was relatively straight forward, as I quickly identified that it just required a topological sort of the steps. For a minute or so I forgot how the algorithm worked (is it like a breadth first search starting from the root? or from the tail? or is it different?), but I've implemented it in Python before so I eventually recalled how it worked. The algorithm follows easily from the logic of the example they included.\n",
    "\n",
    "The second star required just adding some additional components to handle the time-tracking logic separately. Essentially I just stored a dictionary of (letter, time-left) pairs to keep track of what is getting worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFKEGNOVATIHXYZRMCJDLSUPWQ\n",
      "BFKVEGAOTNYIHXZRMCJLDSUPWQ\n",
      "1020\n"
     ]
    }
   ],
   "source": [
    "# first star\n",
    "\n",
    "with open('input/input7.txt') as f:\n",
    "    X = f.readlines()\n",
    "\n",
    "X = list(map(lambda x: (x[5], x[36]), X))\n",
    "\n",
    "letters = set()\n",
    "reqs = defaultdict(set)  # map from a required step to the set of steps that depend on it\n",
    "rev_reqs = defaultdict(set)  # map from a step to the set of steps it requires\n",
    "for req_step, step in X:\n",
    "    reqs[req_step].add(step)\n",
    "    rev_reqs[step].add(req_step)\n",
    "    letters.add(step)\n",
    "    letters.add(req_step)\n",
    "\n",
    "ready = sorted([letter for letter in letters if len(rev_reqs[letter]) == 0])\n",
    "sequence = []\n",
    "while ready:\n",
    "    step = heappop(ready)\n",
    "    sequence.append(step)\n",
    "    for succ in reqs[step]:\n",
    "        rev_reqs[succ].remove(step)\n",
    "        if len(rev_reqs[succ]) == 0:\n",
    "            heappush(ready, succ)\n",
    "\n",
    "print(''.join(sequence))\n",
    "\n",
    "# second star\n",
    "\n",
    "# re-initialize variables\n",
    "sequence = []\n",
    "rev_reqs = defaultdict(set)\n",
    "for req_step, step in X:\n",
    "    rev_reqs[step].add(req_step)\n",
    "ready = sorted([letter for letter in letters if len(rev_reqs[letter]) == 0])\n",
    "\n",
    "times = {letter: 61 + ord(letter) - ord('A') for letter in letters}\n",
    "processing = dict()\n",
    "time = 0\n",
    "while ready or processing:\n",
    "    # more steps that workers can begin work on\n",
    "    while ready and len(processing) < 5:\n",
    "        step = heappop(ready)\n",
    "        processing[step] = times[step]\n",
    "        \n",
    "    # perform time-based updates\n",
    "    keys = list(processing.keys())\n",
    "    for key in keys:\n",
    "        processing[key] -= 1\n",
    "        if processing[key] == 0:\n",
    "            del processing[key]\n",
    "            sequence.append(key)\n",
    "            for succ in reqs[key]:\n",
    "                rev_reqs[succ].remove(key)\n",
    "                if len(rev_reqs[succ]) == 0:\n",
    "                    heappush(ready, succ)\n",
    "\n",
    "    time += 1\n",
    "    \n",
    "print(''.join(sequence))\n",
    "print(time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
